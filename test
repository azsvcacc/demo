locals {
  databricks_clusters = {
    "Experimentation-SM" = {
      cluster_name            = "Experimentation-SM"
      spark_version           = "14.3.x-scala2.12"
      node_type_id            = "Standard_DS3_v2"
      autotermination_minutes = 30
      autoscale = {
        min_workers = 2
        max_workers = 4
      }
      spark_confs = {}
      custom_tags = {
        "cluster-owner-team" = "Experimentation"
        "lifecycle"          = "Permanent"
        "Cluster-type"       = "General"
        "cluster-owner"      = "Paola Piety"
        "Priority"           = "high"
      }
      spark_env_vars = {
        "AWS_SECRET_ACCESS_KEY" = "{{secrets/Experimentation/optimizely-secret-key}}", 
        "AWS_ACCESS_KEY_ID" = "{{secrets/Experimentation/optimizely-access-key}}"
      }
      policy_id      = data.databricks_cluster_policy.shared_compute.id
      runtime_engine = "PHOTON"
      azure_attributes = {
        availability = "SPOT_WITH_FALLBACK_AZURE"
      }
    }
